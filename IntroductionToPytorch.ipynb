{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroductionToPytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNvS66AaV3l0NrDpoHzqXuO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirbrhm/Deep-Learning/blob/main/IntroductionToPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzuaLseOjmfk"
      },
      "source": [
        "import torch \r\n",
        "import numpy as np \r\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "takjcKhLmt4m"
      },
      "source": [
        "## Initialize Tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCEqIvGem67a",
        "outputId": "bf83a0b5-8e25-40a8-baed-7f4f0d3f069e"
      },
      "source": [
        "x = torch.ones(3,2)\r\n",
        "print(x) \r\n",
        "x = torch.zeros(3,2)\r\n",
        "print(x) \r\n",
        "x = torch.rand(3,2) \r\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[0.2613, 0.3126],\n",
            "        [0.6808, 0.5001],\n",
            "        [0.2343, 0.0960]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FikAiFPkmvzI",
        "outputId": "6116d61e-078b-4651-8d39-cab22c1024c6"
      },
      "source": [
        "x = torch.empty(3,2) # will allocate memory, but not initialize it. Garbage will be stored \r\n",
        "print(x) \r\n",
        "y = torch.zeros_like(x) # use the shape of x \r\n",
        "print(y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.1718e-29, 3.0757e-41],\n",
            "        [3.3631e-44, 0.0000e+00],\n",
            "        [       nan, 1.0000e+00]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEm5jc2Mju-a",
        "outputId": "84429e8b-2f3d-4890-c655-a893312ef2d1"
      },
      "source": [
        "x = torch.linspace(0,1,5)\r\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSQpZNnsn_Oc",
        "outputId": "c13c25e5-eb35-462d-afe7-5c94d12bb092"
      },
      "source": [
        "x = torch.tensor([[1,2],[3,4],[5,6]]) # specifying each row in each square brackets \r\n",
        "print(x) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JvyCBcXoSS_"
      },
      "source": [
        "## Slicing of Tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elSXoTQKoehZ",
        "outputId": "b561abe8-1634-4a42-bb01-4fc7c814cbd9"
      },
      "source": [
        "print(x.size())\r\n",
        "print(x[:,1])\r\n",
        "print(x[0,:])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2])\n",
            "tensor([2, 4, 6])\n",
            "tensor([1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_g72sa3ooQZ",
        "outputId": "0077d52d-925c-401a-a094-2d56a7decd4c"
      },
      "source": [
        "y = x[1,1] \r\n",
        "print(y) \r\n",
        "print(y.item()) # to get the numerical value. "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4)\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Wlb6hzrGvI"
      },
      "source": [
        "## Reshaping Tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qdTw3K5rKP7",
        "outputId": "e5f53db2-b242-40b7-a824-01f9e3a984c2"
      },
      "source": [
        "print(x) \r\n",
        "y = x.view(2,3)\r\n",
        "print(y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyBh1_CzrQCW",
        "outputId": "249a2627-1e36-466e-9001-392cdf1ba728"
      },
      "source": [
        "y = x.view(6,-1) # I know only one of the dimensions, the other dimension is found appropriately\r\n",
        "print(y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5],\n",
            "        [6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_gK1rsCr9fT"
      },
      "source": [
        "We can do the basic '+' , '-' and '*' with tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4ptNMxexpCb"
      },
      "source": [
        "x = torch.ones(3,2) \r\n",
        "y = torch.ones(3,2) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDurB_YGriro",
        "outputId": "d5421b96-db06-4d36-c6e2-fea1c8a78f29"
      },
      "source": [
        "z = y.add(x) \r\n",
        "print(z) \r\n",
        "print(y) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3OlO6K_pGgs",
        "outputId": "5e1b46e0-7aee-4e69-c6b2-4bb95db89f5b"
      },
      "source": [
        "z = y.add_(x) # in-place addition, updates the y also\r\n",
        "print(z) \r\n",
        "print(y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlrVaZ8pF5pK"
      },
      "source": [
        "## Numpy <> PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXcDCqoFF9IA",
        "outputId": "06f53b4b-e922-42fc-adf2-1a1694c49d99"
      },
      "source": [
        "x_np = x.numpy() \r\n",
        "print(x_np) \r\n",
        "print(type(x), type(x_np))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]]\n",
            "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpjwhkLex-Tw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e955854b-245c-47e9-ca9a-c66d45e99949"
      },
      "source": [
        "a = np.random.rand(5) \r\n",
        "print(a) \r\n",
        "a_pt = torch.from_numpy(a) \r\n",
        "print(a) \r\n",
        "print(type(a),type(a_pt)) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04692011 0.71296832 0.85099411 0.2536531  0.37421834]\n",
            "[0.04692011 0.71296832 0.85099411 0.2536531  0.37421834]\n",
            "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSolsZ5WHQku",
        "outputId": "9a144c8d-7c9c-4246-9c14-e720d74a99d5"
      },
      "source": [
        "np.add(a,1,out=a) \r\n",
        "print(a) \r\n",
        "print(a_pt) # even a_pt is updated, so a_pt was not really just a copy but have the same memory location"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.04692011 1.71296832 1.85099411 1.2536531  1.37421834]\n",
            "tensor([1.0469, 1.7130, 1.8510, 1.2537, 1.3742], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOulANxCHh0g",
        "outputId": "29717f51-ec17-46d8-b643-2115b00f196e"
      },
      "source": [
        "%%time \r\n",
        "for i in range(100):\r\n",
        "  a = np.random.rand(100,100) \r\n",
        "  b = np.random.rand(100,100) \r\n",
        "  c = a*b # element wise multiplication, for matrix mulitiplication use matmul "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 26 ms, sys: 1.79 ms, total: 27.8 ms\n",
            "Wall time: 40 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkzffvroH_J9",
        "outputId": "22c8f994-9bfc-4941-f883-68df3db3e84a"
      },
      "source": [
        "%%time \r\n",
        "for i in range(100):\r\n",
        "  a = torch.randn(100,100) \r\n",
        "  b = torch.randn(100,100)\r\n",
        "  c = a*b "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 21.2 ms, sys: 128 µs, total: 21.4 ms\n",
            "Wall time: 23.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5Ux3S_WIOab",
        "outputId": "38af328c-bb74-462d-cef1-524f7d029c6c"
      },
      "source": [
        "%%time \r\n",
        "for i in range(100):\r\n",
        "  a = np.random.rand(1000,1000) \r\n",
        "  b = np.random.rand(1000,1000) \r\n",
        "  c = a+b "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.59 s, sys: 9.74 ms, total: 1.6 s\n",
            "Wall time: 1.61 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFsFDZWVI9mm",
        "outputId": "056a1730-50f8-487f-9cdd-331be0a9ca47"
      },
      "source": [
        "%%time \r\n",
        "for i in range(100):\r\n",
        "  a = torch.randn(1000,1000) \r\n",
        "  b = torch.randn(1000,1000)\r\n",
        "  c = a+b "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.91 s, sys: 9.86 ms, total: 1.92 s\n",
            "Wall time: 1.92 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_0s06I6Jmc6"
      },
      "source": [
        "## CUDA Support"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIH0VOL9JpMg",
        "outputId": "76a7e855-44dc-4a4d-de8e-f11e797fa181"
      },
      "source": [
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dedHW-3JBod",
        "outputId": "d80b1db3-7de7-4e23-e028-42b539040e2d"
      },
      "source": [
        "print(torch.cuda.device(0))\r\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.cuda.device object at 0x7fe92dfc1090>\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHwE66CiKSpx"
      },
      "source": [
        "cuda0 = torch.device(\"cuda:0\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO9mfW_kKnXV",
        "outputId": "9a40b2ab-f0ee-486e-d368-6a2bea5ea45d"
      },
      "source": [
        "a = torch.ones(3,2,device=cuda0)\r\n",
        "b = torch.ones(3,2,device=cuda0)\r\n",
        "c = a + b \r\n",
        "print(c)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxs6fa_oKuo3",
        "outputId": "532bdfee-08e0-41da-8415-6aeec68c9fa4"
      },
      "source": [
        "%%time \r\n",
        "for i in range(10):\r\n",
        "  a = np.random.rand(10000,10000) \r\n",
        "  b = np.random.rand(10000,10000) \r\n",
        "  np.add(b,a) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16.1 s, sys: 444 ms, total: 16.6 s\n",
            "Wall time: 16.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAH9z8AkLKD8",
        "outputId": "b36d2563-4d56-45e7-d768-0052ac1d1078"
      },
      "source": [
        "%%time \r\n",
        "for i in range(10):\r\n",
        "  a_cpu = torch.rand(10000,10000) \r\n",
        "  b_cpu = torch.rand(10000,10000) \r\n",
        "  b_cpu.add_(a_cpu)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 12.1 s, sys: 179 ms, total: 12.3 s\n",
            "Wall time: 12.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n74FP5rrLhR4",
        "outputId": "9ade681a-33f1-4d6f-ee7c-80929fccaeb3"
      },
      "source": [
        "%%time \r\n",
        "for i in range(10):\r\n",
        "  a = torch.rand(10000,10000, device = cuda0) \r\n",
        "  b = torch.rand(10000,10000, device = cuda0) \r\n",
        "  b.add_(a)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 950 µs, sys: 3 ms, total: 3.95 ms\n",
            "Wall time: 7.06 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC65ixcpMIm1"
      },
      "source": [
        "The Usage of GPU can accelerate the process 10s of thousands of times faster than CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY8XOdHNMqHZ"
      },
      "source": [
        "## AutoGrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B2z17MfMrms",
        "outputId": "48684ca7-3f9d-42dc-c4ca-c68f312c758d"
      },
      "source": [
        "x = torch.ones([3,2],requires_grad=True) # telling torch that I might later differentiate x \r\n",
        "print(x)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV32aFuCMz4F",
        "outputId": "60583a71-879d-4669-c5d3-9a244559b84b"
      },
      "source": [
        "y = x + 5 \r\n",
        "print(y) # we see add backwards in the output, it is doing the book keeping that y is a function of x "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6., 6.],\n",
            "        [6., 6.],\n",
            "        [6., 6.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu2AVNgZNEqM",
        "outputId": "21acd3cb-e7b3-4f06-a168-d7769166c50d"
      },
      "source": [
        "z = y*y + 1 \r\n",
        "print(z)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[37., 37.],\n",
            "        [37., 37.],\n",
            "        [37., 37.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpvA9F1RNJjH",
        "outputId": "d087e185-de57-43c9-9114-02f23c23cc60"
      },
      "source": [
        "t = torch.sum(z)\r\n",
        "print(t)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(222., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHCZrZmKNqgt"
      },
      "source": [
        "We have basically simulated a forward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot-Z3hDRNdYK"
      },
      "source": [
        "t.backward() # pytorch does some internal computations "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwugHiaCNyAP",
        "outputId": "1e8cfac4-9661-47e6-d719-9643cb94b727"
      },
      "source": [
        "print(x.grad) # derivative of t wrt to x , calculated at x = 1 (initial value)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[12., 12.],\n",
            "        [12., 12.],\n",
            "        [12., 12.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pSnyKAUOB6x",
        "outputId": "7f250dd4-9c24-4e6b-e412-ab90da3a69ee"
      },
      "source": [
        "x = torch.ones([3,2],requires_grad=True)\r\n",
        "y = x + 5 \r\n",
        "r = 1/(1 + torch.exp(-y)) \r\n",
        "print(r) \r\n",
        "s = torch.sum(r)\r\n",
        "s.backward()\r\n",
        "print(x.grad) "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9975, 0.9975],\n",
            "        [0.9975, 0.9975],\n",
            "        [0.9975, 0.9975]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0025, 0.0025],\n",
            "        [0.0025, 0.0025],\n",
            "        [0.0025, 0.0025]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXYWr628RdLq"
      },
      "source": [
        "If we have to directly compute the grad of a tensor then we must pass an argument : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffhfgo0UQnrK",
        "outputId": "f3f74c67-e79a-42fc-88d1-ab9325c6caff"
      },
      "source": [
        "x = torch.ones([3,2],requires_grad=True)\r\n",
        "y = x + 5 \r\n",
        "r = 1/(1 + torch.exp(-y)) \r\n",
        "a = torch.ones([3,2])\r\n",
        "r.backward(a) # what it does is dr/dx * a. So we choose a = unity, so things remain cool. We will revisit this. \r\n",
        "print(x.grad) "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0025, 0.0025],\n",
            "        [0.0025, 0.0025],\n",
            "        [0.0025, 0.0025]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvqLM5YZXEND"
      },
      "source": [
        "$ \\frac{\\partial s}{\\partial x} = \\frac{\\partial s}{\\partial r} . \\frac{\\partial r}{\\partial x} $ \\\r\n",
        "For the above code $a$ represents $ \\frac{\\partial s}{\\partial r} $ and $x.grad(a)$ directly gives us $\\frac{\\partial s}{\\partial x}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC0moL-WYbj-"
      },
      "source": [
        "## AutoGrad example that looks like what we have been doing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZJbCdbFRv8s"
      },
      "source": [
        "x = torch.randn([20,1], requires_grad=True) \r\n",
        "y = 3*x - 2 # ground truth "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb2kGhE3YpFu"
      },
      "source": [
        "w = torch.tensor([1.], requires_grad=True)\r\n",
        "b = torch.tensor([1.], requires_grad=True)\r\n",
        "\r\n",
        "y_hat = w*x + b # hypothesis \r\n",
        "\r\n",
        "loss = torch.sum((y_hat-y)**2) "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkq-5Op-ZIB-",
        "outputId": "a34c152e-0339-4117-b6fc-56bc0a12a9db"
      },
      "source": [
        "print(loss)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(294.6115, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsjFlFhjZTxN"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJEX6Q0kZbKq",
        "outputId": "688979f0-dc41-404f-d37e-9f3c54f92f68"
      },
      "source": [
        "print(w.grad,b.grad)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-107.9753]) tensor([124.4242])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy3z2eOUaNRm"
      },
      "source": [
        "## Do it in a loop "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTShpDWyaQiL"
      },
      "source": [
        "learning_rate = 0.01 \r\n",
        "\r\n",
        "w = torch.tensor([1.], requires_grad=True) # 1. is written to treat it as a number \r\n",
        "b = torch.tensor([1.], requires_grad=True) # initializing both to 1 \r\n",
        "\r\n",
        "print(w.item(),b.item())\r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "\r\n",
        "  x = torch.randn([20,1]) \r\n",
        "  y = 3*x - 2 \r\n",
        "\r\n",
        "  y_hat = w*x + b # hypothesis \r\n",
        "  loss = torch.sum((y_hat-y)**2)\r\n",
        "\r\n",
        "  loss.backward()\r\n",
        "\r\n",
        "  with torch.no_grad(): # to tell torch that it no longer needs to do the book keeping and our forward pass has been completed \r\n",
        "    w -= learning_rate * w.grad # now just thought of as variable updates and not a new function written in terms of the old functions \r\n",
        "    b -= learning_rate * b.grad\r\n",
        "\r\n",
        "    w.grad.zero_()\r\n",
        "    b.grad.zero_() # reinitializing them to 0 for the next iteration \r\n",
        "  \r\n",
        "  print(w.item(),b.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWDYYIe3cVz-"
      },
      "source": [
        "## Doing it for a large problem "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICkg8HBcf0pu"
      },
      "source": [
        "Every tensors needs to be created into the GPU for fast calculations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2o9fEx1b6BP"
      },
      "source": [
        "%%time \r\n",
        "learning_rate = 0.001 \r\n",
        "N = 100000\r\n",
        "epochs = 200\r\n",
        "\r\n",
        "w = torch.rand([N], requires_grad=True, device=cuda0) \r\n",
        "b = torch.ones([1], requires_grad=True, device=cuda0) \r\n",
        "\r\n",
        "print(torch.mean(w).item(), b.item())\r\n",
        "\r\n",
        "for i in range(epochs):\r\n",
        "  x = torch.randn([N], device=cuda0) \r\n",
        "  y = torch.dot(3*torch.ones([N],device=cuda0), x) - 2 \r\n",
        "\r\n",
        "  y_hat = torch.dot(w,x) + b \r\n",
        "  loss = torch.sum((y_hat-y)**2)\r\n",
        "\r\n",
        "  loss.backward()\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    w -= learning_rate * w.grad\r\n",
        "    b -= learning_rate * b.grad \r\n",
        "\r\n",
        "    w.grad.zero_()\r\n",
        "    b.grad.zero_()\r\n",
        "\r\n",
        "    print(torch.mean(w).item(), b.item())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}